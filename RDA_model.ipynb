{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AnLEp42wb6qz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in c:\\users\\white\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.13.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xmltodict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KoHnELaWbylb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import sys\n",
        "import requests\n",
        "import xmltodict\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import shutil\n",
        "import copy\n",
        "import time\n",
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as et\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.models import * \n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYElt1tFfiPp",
        "outputId": "5631c87f-b9d3-45cf-8226-126f4c8ccbd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM7fZjcLKCbp"
      },
      "source": [
        "#### <b>Mix Style Library</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ZlgYHu-KCFh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from contextlib import contextmanager\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def deactivate_mixstyle(m):\n",
        "    if type(m) == MixStyle:\n",
        "        m.set_activation_status(False)\n",
        "\n",
        "\n",
        "def activate_mixstyle(m):\n",
        "    if type(m) == MixStyle:\n",
        "        m.set_activation_status(True)\n",
        "\n",
        "\n",
        "def random_mixstyle(m):\n",
        "    if type(m) == MixStyle:\n",
        "        m.update_mix_method(\"random\")\n",
        "\n",
        "\n",
        "def crossdomain_mixstyle(m):\n",
        "    if type(m) == MixStyle:\n",
        "        m.update_mix_method(\"crossdomain\")\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def run_without_mixstyle(model):\n",
        "    # Assume MixStyle was initially activated\n",
        "    try:\n",
        "        model.apply(deactivate_mixstyle)\n",
        "        yield\n",
        "    finally:\n",
        "        model.apply(activate_mixstyle)\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def run_with_mixstyle(model, mix=None):\n",
        "    # Assume MixStyle was initially deactivated\n",
        "    if mix == \"random\":\n",
        "        model.apply(random_mixstyle)\n",
        "\n",
        "    elif mix == \"crossdomain\":\n",
        "        model.apply(crossdomain_mixstyle)\n",
        "\n",
        "    try:\n",
        "        model.apply(activate_mixstyle)\n",
        "        yield\n",
        "    finally:\n",
        "        model.apply(deactivate_mixstyle)\n",
        "\n",
        "\n",
        "class MixStyle(nn.Module):\n",
        "    \"\"\"MixStyle.\n",
        "    Reference:\n",
        "      Zhou et al. Domain Generalization with MixStyle. ICLR 2021.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=0.5, alpha=0.1, eps=1e-6, mix=\"random\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          p (float): probability of using MixStyle.\n",
        "          alpha (float): parameter of the Beta distribution.\n",
        "          eps (float): scaling parameter to avoid numerical issues.\n",
        "          mix (str): how to mix.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.beta = torch.distributions.Beta(alpha, alpha)\n",
        "        self.eps = eps\n",
        "        self.alpha = alpha\n",
        "        self.mix = mix\n",
        "        self._activated = True\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"MixStyle(p={self.p}, alpha={self.alpha}, eps={self.eps}, mix={self.mix})\"\n",
        "        )\n",
        "\n",
        "    def set_activation_status(self, status=True):\n",
        "        self._activated = status\n",
        "\n",
        "    def update_mix_method(self, mix=\"random\"):\n",
        "        self.mix = mix\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self._activated:\n",
        "            return x\n",
        "\n",
        "        if random.random() > self.p:\n",
        "            return x\n",
        "\n",
        "        B = x.size(0)\n",
        "\n",
        "        mu = x.mean(dim=[2, 3], keepdim=True)\n",
        "        var = x.var(dim=[2, 3], keepdim=True)\n",
        "        sig = (var + self.eps).sqrt()\n",
        "        mu, sig = mu.detach(), sig.detach()\n",
        "        x_normed = (x-mu) / sig\n",
        "\n",
        "        lmda = self.beta.sample((B, 1, 1, 1))\n",
        "        lmda = lmda.to(x.device)\n",
        "\n",
        "        if self.mix == \"random\":\n",
        "            # random shuffle\n",
        "            perm = torch.randperm(B)\n",
        "\n",
        "        elif self.mix == \"crossdomain\":\n",
        "            # split into two halves and swap the order\n",
        "            perm = torch.arange(B - 1, -1, -1)  # inverse index\n",
        "            perm_b, perm_a = perm.chunk(2)\n",
        "            perm_b = perm_b[torch.randperm(perm_b.shape[0])]\n",
        "            perm_a = perm_a[torch.randperm(perm_a.shape[0])]\n",
        "            perm = torch.cat([perm_b, perm_a], 0)\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        mu2, sig2 = mu[perm], sig[perm]\n",
        "        mu_mix = mu*lmda + mu2 * (1-lmda)\n",
        "        sig_mix = sig*lmda + sig2 * (1-lmda)\n",
        "\n",
        "        return x_normed*sig_mix + mu_mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xizXDUdsKaoi"
      },
      "source": [
        "#### <b>Parameter</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h9v_atTAKd65"
      },
      "outputs": [],
      "source": [
        "Parameter = {\n",
        "      \"model\":\"resnet18\",\n",
        "      \"weight\":\"IMAGENET1K_V1\",\n",
        "      \"Loss Function\":\"CrossEntropyLoss\",\n",
        "      \"optimizer\":{\"model\":\"Adam\",\"lr\":0.001,\"momentum\":0.9},\n",
        "      \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1},\n",
        "      \"data_condition\":{\"mode\":0}, # # 0 : y축 분류, 1 : x축 분류, 2 : x,y 축 분류인데 test 를 train이 아닌 전부로, 3 : x,y 축 분류인데 test 를 ytest 에 해당하는 값들로\n",
        "      \"data_feature\":{\"xtrain_angle\":[i for i in range(1,15)],\"xtest_angle\":[i for i in range(15,25)],\"ytrain_angle\":[0,30],\"ytest_angle\":[60]},\n",
        "      \"Domain_Generalization\":0, # Domain Generalization (도메인 일반화, 데이터 증진 or mixstyle 등)\n",
        "    }\n",
        "\n",
        "def set_parameter(Hp):\n",
        "    global Parameter\n",
        "    Parameter=Hp\n",
        "    return Hp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQRhgn-xKTTI"
      },
      "source": [
        "#### <b>ResNet Architecture</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xZ_he3ZMJv_H"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import Any, Callable, List, Optional, Type, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "from torchvision.transforms._presets import ImageClassification\n",
        "from torchvision.utils import _log_api_usage_once\n",
        "from torchvision.models._api import register_model, Weights, WeightsEnum\n",
        "from torchvision.models._meta import _IMAGENET_CATEGORIES\n",
        "from torchvision.models._utils import _ovewrite_named_param, handle_legacy_interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DwT_yhXNKpQK"
      },
      "outputs": [],
      "source": [
        "__all__ = [\n",
        "    \"ResNet\",\n",
        "    \"ResNet18_Weights\",\n",
        "    \"ResNet34_Weights\",\n",
        "    \"resnet18\",\n",
        "    \"resnet34\",\n",
        "]\n",
        "\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        _log_api_usage_once(self)\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\n",
        "                \"replace_stride_with_dilation should be None \"\n",
        "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
        "            )\n",
        "\n",
        "            \n",
        "        if Parameter[\"Domain_Generalization\"]==1:\n",
        "            #print(\"SDFSDF\")\n",
        "            ## MixStyle 정의\n",
        "            self.mixstyle = MixStyle(p=0.5, alpha=0.1)\n",
        "\n",
        "\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck) and m.bn3.weight is not None:\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock) and m.bn2.weight is not None:\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        "\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block: Type[Union[BasicBlock, Bottleneck]],\n",
        "        planes: int,\n",
        "        blocks: int,\n",
        "        stride: int = 1,\n",
        "        dilate: bool = False,\n",
        "    ) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
        "            )\n",
        "        )\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    self.inplanes,\n",
        "                    planes,\n",
        "                    groups=self.groups,\n",
        "                    base_width=self.base_width,\n",
        "                    dilation=self.dilation,\n",
        "                    norm_layer=norm_layer,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        ## update \n",
        "        if Parameter[\"Domain_Generalization\"]==1:\n",
        "            #print(\"#####\")\n",
        "            x = self.mixstyle(x)\n",
        "            \n",
        "        x = self.layer2(x)\n",
        "\n",
        "        if Parameter[\"Domain_Generalization\"]==1:\n",
        "            #print(\"@@@@@\")\n",
        "            x = self.mixstyle(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(\n",
        "    block: Type[Union[BasicBlock, Bottleneck]],\n",
        "    layers: List[int],\n",
        "    weights: Optional[WeightsEnum],\n",
        "    progress: bool,\n",
        "    **kwargs: Any,\n",
        ") -> ResNet:\n",
        "    if weights is not None:\n",
        "        #print(weights)\n",
        "        _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
        "\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "_COMMON_META = {\n",
        "    \"min_size\": (1, 1),\n",
        "    \"categories\": _IMAGENET_CATEGORIES,\n",
        "}\n",
        "\n",
        "\n",
        "class ResNet18_Weights(WeightsEnum):\n",
        "    IMAGENET1K_V1 = Weights(\n",
        "        url=\"https://download.pytorch.org/models/resnet18-f37072fd.pth\",\n",
        "        transforms=partial(ImageClassification, crop_size=224),\n",
        "        meta={\n",
        "            **_COMMON_META,\n",
        "            \"num_params\": 11689512,\n",
        "            \"recipe\": \"https://github.com/pytorch/vision/tree/main/references/classification#resnet\",\n",
        "            \"_metrics\": {\n",
        "                \"ImageNet-1K\": {\n",
        "                    \"acc@1\": 69.758,\n",
        "                    \"acc@5\": 89.078,\n",
        "                }\n",
        "            },\n",
        "            \"_docs\": \"\"\"These weights reproduce closely the results of the paper using a simple training recipe.\"\"\",\n",
        "        },\n",
        "    )\n",
        "    DEFAULT = IMAGENET1K_V1\n",
        "\n",
        "\n",
        "class ResNet34_Weights(WeightsEnum):\n",
        "    IMAGENET1K_V1 = Weights(\n",
        "        url=\"https://download.pytorch.org/models/resnet34-b627a593.pth\",\n",
        "        transforms=partial(ImageClassification, crop_size=224),\n",
        "        meta={\n",
        "            **_COMMON_META,\n",
        "            \"num_params\": 21797672,\n",
        "            \"recipe\": \"https://github.com/pytorch/vision/tree/main/references/classification#resnet\",\n",
        "            \"_metrics\": {\n",
        "                \"ImageNet-1K\": {\n",
        "                    \"acc@1\": 73.314,\n",
        "                    \"acc@5\": 91.420,\n",
        "                }\n",
        "            },\n",
        "            \"_docs\": \"\"\"These weights reproduce closely the results of the paper using a simple training recipe.\"\"\",\n",
        "        },\n",
        "    )\n",
        "    DEFAULT = IMAGENET1K_V1\n",
        "\n",
        "\n",
        "@handle_legacy_interface(weights=(\"pretrained\", ResNet18_Weights.IMAGENET1K_V1))\n",
        "def Resnet18(*, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:\n",
        "    \n",
        "    weights = ResNet18_Weights.verify(weights)\n",
        "    return _resnet(BasicBlock, [2, 2, 2, 2], weights, progress, **kwargs)\n",
        "\n",
        "\n",
        "@handle_legacy_interface(weights=(\"pretrained\", ResNet34_Weights.IMAGENET1K_V1))\n",
        "def Resnet34(*, weights: Optional[ResNet34_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:\n",
        "    \n",
        "    weights = ResNet34_Weights.verify(weights)\n",
        "    return _resnet(BasicBlock, [3, 4, 6, 3], weights, progress, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jA1Bp7LZK1NI"
      },
      "outputs": [],
      "source": [
        "# The dictionary below is internal implementation detail and will be removed in v0.15\n",
        "from torchvision.models._utils import _ModelURLs\n",
        "\n",
        "\n",
        "model_urls = _ModelURLs(\n",
        "    {\n",
        "        \"resnet18\": ResNet18_Weights.IMAGENET1K_V1.url,\n",
        "        \"resnet34\": ResNet34_Weights.IMAGENET1K_V1.url\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M1qG4BDQLAoZ"
      },
      "outputs": [],
      "source": [
        "#resnet18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuRJI5LPbBqS",
        "outputId": "c8e498aa-4d49-4a43-fb23-70c967b14a40"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN1wPQ-CbnZ0"
      },
      "source": [
        "특정 폴더 기준으로 들어감, inital_path 설정해야됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z51DK84oMDHw"
      },
      "outputs": [],
      "source": [
        "class market_product_identification():\n",
        "\n",
        "    def __init__(self,inital_path,using_category,data_feature,Data_augmentation):\n",
        "\n",
        "        # Data Frame 없이 할 수 있음 (바꾸기)\n",
        "        # 각도별 path를 저장하고 불러올때 불러오기\n",
        "        # Data to use in xml file\n",
        "        self.category=using_category\n",
        "\n",
        "        self.Data_augmentation=Data_augmentation\n",
        "\n",
        "        self.a0_path=[]\n",
        "        self.a30_path=[]\n",
        "        self.a60_path=[]\n",
        "        self.nb={}\n",
        "        self.nl_idx={}\n",
        "\n",
        "        #file initial position\n",
        "        self.inital_path=inital_path\n",
        "\n",
        "        self.data_path=self.inital_path+\"dataset/\"\n",
        "\n",
        "        #DataFrame creation and data labeling\n",
        "        self.object_type,self.object_stack,self.object_count,self.DataFrame=self.new_label(self.produce_DataFrame())\n",
        "        #print(self.DataFrame)\n",
        "        #print(self.DataFrame)\n",
        "        #print(self.DataFrame.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.ytrain_angle=data_feature[\"ytrain_angle\"]\n",
        "        self.ytest_angle=data_feature[\"ytest_angle\"]\n",
        "\n",
        "        #print(self.DataFrame)\n",
        "        self.train,self.test=self.data_dividing(self.DataFrame)\n",
        "\n",
        "        #print(f\"train shape : {self.train.shape}\")\n",
        "        #print(f\"test shape : {self.test.shape}\")\n",
        "\n",
        "        #\"\"\"\n",
        "        #Generate transform for each data set\n",
        "        self.train_transform,self.val_transform,self.test_transform=self.transform(256)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # return market_product_identification's variable\n",
        "\n",
        "\n",
        "    # Find the file corresponding to the path\n",
        "    def find_list(self,path):\n",
        "        return os.listdir(path)\n",
        "    \n",
        "    # DataFrame creation\n",
        "    def produce_DataFrame(self):\n",
        "\n",
        "      #print(self.nb)\n",
        "    \n",
        "\n",
        "      img_path=self.data_path\n",
        "\n",
        "\n",
        "      #label_path=self.inital_path+\"sample_data_food/라벨링데이터/\"\n",
        "      #image_path=self.inital_path+\"sample_data_food/원천데이터/\"\n",
        "\n",
        "      #print(\"produce_dataframe\")\n",
        "\n",
        "      dataframe=np.array([])\n",
        "      dataframe = np.empty((0,len(self.category)), int)\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      for name in self.find_list(img_path):\n",
        "\n",
        "          for angle in ['0','30','60']:\n",
        "\n",
        "            for data in self.find_list(img_path+name+'/'+angle+'/'):\n",
        "\n",
        "              DT=data.split(\"_\")\n",
        "            \n",
        "              #'prod_nm','file_name','yangle','path','rotation'\n",
        "              Da=[name, data, int(DT[1]), img_path+name+'/'+angle+'/'+data,0]\n",
        "              dataframe=np.append(dataframe,np.array([Da]),axis=0)\n",
        "              self.nb[name]=str(data.split(\"_\")[0])\n",
        "              self.nl_idx[str(data.split(\"_\")[0])]=name\n",
        "\n",
        "              if angle=='0':\n",
        "                self.a0_path.append(img_path+name+'/'+angle+'/'+data)\n",
        "              elif angle=='30':\n",
        "                self.a30_path.append(img_path+name+'/'+angle+'/'+data)\n",
        "              elif angle=='60':\n",
        "                self.a60_path.append(img_path+name+'/'+angle+'/'+data)\n",
        "\n",
        "\n",
        "            \n",
        "      return pd.DataFrame(data=dataframe,columns=self.category)\n",
        "    \n",
        "    # data labeling\n",
        "    def new_label(self,DataFrame):\n",
        "        object_type={}\n",
        "        idx=0\n",
        "        object_stack=[]\n",
        "        for i in range(DataFrame.shape[0]):\n",
        "            data=DataFrame.iloc[i][\"prod_nm\"]\n",
        "            ZZ=DataFrame.iloc[i][\"file_name\"]\n",
        "            \n",
        "            if not data in object_type:\n",
        "                object_type[data]=idx\n",
        "                object_stack.append({'0':0,'30':0,'60':0})\n",
        "                object_stack[object_type[data]][ZZ.split(\"_\")[1]]+=1\n",
        "                idx+=1\n",
        "            else:\n",
        "                #print(ZZ.split(\"_\"))\n",
        "                object_stack[object_type[data]][ZZ.split(\"_\")[1]]+=1\n",
        "            #print(object_stack)\n",
        "\n",
        "            A=DataFrame.iloc[i][\"prod_nm\"]\n",
        "            self.nl_idx[self.nb[A]]=object_type[data]\n",
        "            DataFrame.iloc[i][\"prod_nm\"]=object_type[data]\n",
        " \n",
        "        \n",
        "        DataFrame= DataFrame.sample(frac=1)  # row 전체 shuffle\n",
        "        DataFrame = DataFrame.sample(frac=1).reset_index(drop=True)  # shuffling하고 index reset\n",
        "\n",
        "\n",
        "        #print(\"finish\")\n",
        "        #print(object_stack)\n",
        "\n",
        "        return object_type,object_stack,len(object_stack),DataFrame\n",
        "    \n",
        "\n",
        "    # Dividing of DataFrame\n",
        "    def data_dividing(self,DataFrame):\n",
        "        #self.object_type,self.object_stack,self.obejct_count,self.DataFrame\n",
        "\n",
        "        train=np.array([])\n",
        "        train = np.empty((0,len(self.category)), int)\n",
        "        test=np.array([])\n",
        "        test = np.empty((0,len(self.category)), int)\n",
        "        #print(dict(pd.iloc[0]))\n",
        "        for i in range(DataFrame.shape[0]):\n",
        "            data=DataFrame.iloc[i][\"file_name\"]\n",
        "\n",
        "            Ip=[]\n",
        "            for g in range(len(self.category)):Ip.append(DataFrame.iloc[i][self.category[g]])\n",
        "            ya=int(DataFrame.iloc[i][\"yangle\"])\n",
        "            #print(i,xa,ya)\n",
        "\n",
        "            if ya in self.ytrain_angle:\n",
        "                train=np.append(train,np.array([Ip]),axis=0)\n",
        "\n",
        "            elif ya in self.ytest_angle:\n",
        "                test=np.append(test,np.array([Ip]),axis=0)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        train=pd.DataFrame(data=train,columns=self.category)\n",
        "        test=pd.DataFrame(data=test,columns=self.category)\n",
        "        #print(\"train\")\n",
        "        #print(train)\n",
        "        #print(\"Test\")\n",
        "        #print(test)\n",
        "\n",
        "        return train,test\n",
        "    \n",
        "    #Generate transform for each data set\n",
        "    def transform(self,size=256):\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "        ])\n",
        "\n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "        ])\n",
        "\n",
        "        test_transform = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "        ])\n",
        "        return train_transform,val_transform,test_transform\n",
        "    \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KV2hJuHmZoX6"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,label,transform=None,tt={\"mode\":\"train\",\"angle\":-1},a0_path=[],a30_path=[],a60_path=[],nl_idx=0,Data_augmentation={}):\n",
        "    self.label_data=label\n",
        "    self.nl_idx=nl_idx\n",
        "    self.Data_augmentation=Data_augmentation\n",
        "    self.transform=transform\n",
        "    self.path={\"0\":a0_path,\"30\":a30_path,\"60\":a60_path}\n",
        "    self.path_l={\"0\":len(a0_path),\"30\":len(a30_path),\"60\":len(a60_path)}\n",
        "    self.mode=tt[\"mode\"]\n",
        "    self.test_angle=[]\n",
        "    self.train_angle=[]\n",
        "    for angle in [\"0\",\"30\",\"60\"]:\n",
        "      if angle==str(tt['angle']):\n",
        "        self.test_angle.append(angle)\n",
        "      else:\n",
        "        self.train_angle.append(angle)\n",
        "\n",
        "    self.da_cnt=0\n",
        "    J=list(self.Data_augmentation)\n",
        "    for i in range(len(J)):\n",
        "      self.da_cnt+=self.Data_augmentation[J[i]]\n",
        "\n",
        "    #print(\"#@#@#@#@#@#@#@#@#\")\n",
        "    #print(self.path_l)\n",
        "    #print(self.train_angle)\n",
        "    #print(self.test_angle)\n",
        "\n",
        "    #self.test_angle=test_angle\n",
        "\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    pr=0\n",
        "    #return len(self.label_data)\n",
        "    if self.mode==\"train\":\n",
        "      pr = self.path_l[self.train_angle[0]]+self.path_l[self.train_angle[1]]\n",
        "    else:\n",
        "      pr = self.path_l[self.test_angle[0]]\n",
        "    #return self.path_l[\"0\"]+self.path_l[\"30\"]+self.path_l[\"60\"]#len(self.label_data)\n",
        "\n",
        "    pr*=(self.da_cnt+1)\n",
        "    return pr\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    #label=int(self.label_data.iloc[idx][\"prod_nm\"])\n",
        "    #img_path=self.label_data.iloc[idx][\"path\"]\n",
        "    K=idx//(self.da_cnt+1)\n",
        "\n",
        "\n",
        "    #\"\"\"\n",
        "    if self.mode==\"train\":\n",
        "      if K>=self.path_l[self.train_angle[0]]:\n",
        "        img_path=self.path[self.train_angle[1]][(K-self.path_l[self.train_angle[0]])]\n",
        "      else:\n",
        "        img_path=self.path[self.train_angle[0]][K]\n",
        "\n",
        "    elif self.mode==\"test\":\n",
        "      img_path=self.path[self.test_angle[0]][K]\n",
        "    #\"\"\"\n",
        "\n",
        "    AA=img_path.split(\"/\")\n",
        "    #print(AA[len(AA)-1].split(\"_\")[0])\n",
        "\n",
        "    if (self.mode==\"train\" and str(AA[len(AA)-1].split(\"_\")[1]) in self.test_angle) or (self.mode==\"test\" and str(AA[len(AA)-1].split(\"_\")[1]) in self.train_angle):\n",
        "      print(\"error\")\n",
        "\n",
        "    label=self.nl_idx[AA[len(AA)-1].split(\"_\")[0]]\n",
        "\n",
        "    #if self.lable_data.iloc[idx][\"yangle\"]==self.test_angle:\n",
        "    #print(\"###\",img_path,label)\n",
        "\n",
        "    img=Image.open(img_path)\n",
        "\n",
        "\n",
        "    #\"Data_augmentation\":{\"image_rotation\":0,\"ColorJitter\":0,}\n",
        "    J=list(self.Data_augmentation)\n",
        "    if self.Data_augmentation[\"image_rotation\"]==1 and idx%(self.da_cnt+1)==1:\n",
        "      #print(\"#\")\n",
        "      rotater=transforms.RandomRotation(degrees=(0,180))\n",
        "      IMG=rotater(img)\n",
        "      img=IMG\n",
        "      \n",
        "    elif self.Data_augmentation[\"ColorJitter\"]==1 and idx%(self.da_cnt+1)==2:\n",
        "      #print(\"##\")\n",
        "      jitter = transforms.ColorJitter(brightness=.5, hue=.3)\n",
        "      IMG=jitter(img)\n",
        "      img=IMG\n",
        "\n",
        "    elif self.Data_augmentation[\"RandomHorizontalFlip\"]==1 and idx%(self.da_cnt+1)==3:\n",
        "      #print(\"###\")\n",
        "      hflipper = transforms.RandomHorizontalFlip(p=0.5)\n",
        "      IMG=hflipper(img)\n",
        "\n",
        "    elif self.Data_augmentation[\"RandomVerticalFlip\"]==1 and idx%(self.da_cnt+1)==4:\n",
        "      vflipper = transforms.RandomVerticalFlip(p=0.5)\n",
        "      IMG=vflipper(img)\n",
        "      img=IMG\n",
        "\n",
        "    elif self.Data_augmentation[\"RandomGrayscale\"]==1 and idx%(self.da_cnt+1)==5:\n",
        "      scaler = transforms.RandomGrayscale(p=0.75)\n",
        "      IMG=scaler(img)\n",
        "      img=IMG\n",
        "    \n",
        "\n",
        "\n",
        "    if self.transform:\n",
        "      img=self.transform(img)\n",
        "\n",
        "\n",
        "    return img,label\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fvBMfbQCaE2x"
      },
      "outputs": [],
      "source": [
        "def produce_Dataset(train_v,test_v,batch_size=64,test_angle=0, a0_path=[], a30_path=[], a60_path=[],nl_idx=0,Data_augmentation={}):\n",
        "\n",
        "  train_dataset = CustomDataset(train_v[\"label_data\"],train_v[\"transform\"],tt={\"mode\":\"train\",\"angle\":test_angle},a0_path=a0_path,a30_path=a30_path,a60_path=a60_path,nl_idx=nl_idx,Data_augmentation=Data_augmentation)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "  test_dataset = CustomDataset(test_v[\"label_data\"],test_v[\"transform\"],tt={\"mode\":\"test\",\"angle\":test_angle},a0_path=a0_path,a30_path=a30_path,a60_path=a60_path,nl_idx=nl_idx,Data_augmentation=Data_augmentation)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "  \n",
        "  return {\"dataset\":train_dataset,\"dataloader\":train_dataloader},{\"dataset\":test_dataset,\"dataloader\":test_dataloader}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qVOPqW4BfNxC"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, learning_dataloader,learning_dataset_size,batch_size,train_size,Data_augmentation):\n",
        "\n",
        "  model.train()  # 모델을 학습 모드로 설정\n",
        "\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0 #[0]*(len(MPI.object_stack)+2)\n",
        "  Cor=[0]*(len(train_size)+2)\n",
        "\n",
        "\n",
        "  # 데이터를 반복\n",
        "  for i, batch in enumerate(learning_dataloader):\n",
        "    #print(f\"i : {i}, batch : {batch}.\")\n",
        "      \n",
        "    inputs,labels=batch\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    labels = labels.type(torch.LongTensor).to(device)\n",
        "\n",
        "\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #loss.requires_grad_(True)\n",
        "    loss.backward()\n",
        "    #\"\"\"\n",
        "      \n",
        "    optimizer.step()\n",
        "    \n",
        "    # 통계\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    #print(preds[0].item())\n",
        "    #print(labels.data[0].item())\n",
        "    #print(len(labels.data))\n",
        "    #print(\"##train##\")\n",
        "    #print(len(preds),len(labels.data))\n",
        "    for i in range(len(labels.data)):\n",
        "      if int(preds[i].item())==int(labels.data[i].item()):\n",
        "        Cor[int(labels.data[i].item())]+=1\n",
        "\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  epoch_acc=0\n",
        "  #print(\"train\")\n",
        "  #print(Cor)\n",
        "  #print(train_size)\n",
        "  #print(rotation)\n",
        "\n",
        "\n",
        "  da_cnt=0\n",
        "  J=list(Data_augmentation)\n",
        "  for i in range(len(J)):\n",
        "    da_cnt+=Data_augmentation[J[i]]\n",
        "\n",
        "\n",
        "  for i in range(len(train_size)):\n",
        "    epoch_acc+=Cor[i]/(train_size[i]*(da_cnt+1))\n",
        "\n",
        "\n",
        "  \n",
        "  #print(\"train new\")\n",
        "  #print(Cor,train_size)\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  epoch_loss = running_loss / learning_dataset_size\n",
        "  #print(\"train\",running_corrects.double(),learning_dataset_size)\n",
        "  #epoch_acc = running_corrects.double() / learning_dataset_size\n",
        "  epoch_acc=epoch_acc / len(train_size)\n",
        "  \n",
        "  print(f'train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "  return epoch_loss,epoch_acc,model,optimizer,scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ugaF_R-cfPtp"
      },
      "outputs": [],
      "source": [
        "def test_model(model, criterion,learning_dataloader,learning_dataset_size,test_size,Data_augmentation):\n",
        "  model.eval()  # 모델을 학습 모드로 설정\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "\n",
        "  Cor=[0]*(len(test_size)+2)\n",
        "\n",
        "  # 데이터를 반복\n",
        "  for i, batch in enumerate(learning_dataloader):\n",
        "      \n",
        "    inputs,labels=batch\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.type(torch.LongTensor).to(device)\n",
        "\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # 통계\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    #print(preds[0].item())\n",
        "    #print(labels.data[0].item())\n",
        "    #print(len(labels.data))\n",
        "    #print(\"##test##\")\n",
        "    #print(len(preds),len(labels.data))\n",
        "    for i in range(len(labels.data)):\n",
        "      if int(preds[i].item())==int(labels.data[i].item()):\n",
        "        Cor[int(labels.data[i].item())]+=1\n",
        "\n",
        "  epoch_acc=0\n",
        "\n",
        "  #print(\"test new\")\n",
        "  #print(Cor,test_size)\n",
        "\n",
        "  da_cnt=0\n",
        "  J=list(Data_augmentation)\n",
        "  for i in range(len(J)):\n",
        "    da_cnt+=Data_augmentation[J[i]]\n",
        "\n",
        "\n",
        "  for i in range(len(test_size)):\n",
        "    epoch_acc+=Cor[i]/(test_size[i]*(da_cnt+1))\n",
        "\n",
        "  #print(\"test\")\n",
        "  #print(Cor)\n",
        "  #print(test_size)\n",
        "  #print(rotation)\n",
        "\n",
        "  epoch_loss = running_loss / learning_dataset_size\n",
        "  #print(\"test\",running_corrects.double(),learning_dataset_size)\n",
        "  #epoch_acc = running_corrects.double() / learning_dataset_size \n",
        "  epoch_acc=epoch_acc / len(test_size)\n",
        "\n",
        "  print(f'test Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "  return epoch_loss,epoch_acc,model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Iv9HbDm7fRRy"
      },
      "outputs": [],
      "source": [
        "class dl_Model():\n",
        "  def __init__(self,class_names,device):\n",
        "    self.class_names=class_names\n",
        "    self.device=device\n",
        "\n",
        "  def produce_model(self,Hyperparameter):\n",
        "    \n",
        "    set_parameter(Hyperparameter)\n",
        "\n",
        "    if Hyperparameter[\"model\"]==\"resnet18\":\n",
        "      return self.RESNET18(Hyperparameter)\n",
        "    elif Hyperparameter[\"model\"]==\"resnet34\":\n",
        "      return self.RESNET34(Hyperparameter)\n",
        "    elif Hyperparameter[\"model\"]==\"alexnet\":\n",
        "      return self.ALEXNET(Hyperparameter)\n",
        "    elif Hyperparameter[\"model\"]==\"densenet121\":\n",
        "      return self.DENSENET121(Hyperparameter)\n",
        "    \n",
        "  def DENSENET121(self,Hyperparameter):\n",
        "    \n",
        "    \"\"\"\n",
        "    {\n",
        "      \"model\":\"densenet121\",\n",
        "      \"weight\":\"IMAGENET1K_V1\",\n",
        "      \"Loss Function\":\"CrossEntropyLoss\",\n",
        "      \"optimizer\":{\"model\":\"SGD\",\"lr\":0.001,\"momentum\":0.9},\n",
        "      \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1}\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    model_conv = densenet121(weights=Hyperparameter[\"weight\"])\n",
        "\n",
        "    #model_conv = alexnet(len(self.class_names))\n",
        "    for param in model_conv.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n",
        "    #num_ftrs = model_conv.fc.in_features\n",
        "    #model_conv.fc = nn.Linear(num_ftrs, len(self.class_names))\n",
        "\n",
        "    model_conv = model_conv.to(self.device)\n",
        "\n",
        "    if Hyperparameter[\"Loss Function\"]==\"CrossEntropyLoss\":\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n",
        "    if Hyperparameter[\"optimizer\"][\"model\"]==\"SGD\":\n",
        "      optimizer_conv = optim.SGD(model_conv.parameters(), lr=Hyperparameter[\"optimizer\"][\"lr\"], momentum=Hyperparameter[\"optimizer\"][\"momentum\"])\n",
        "    elif Hyperparameter[\"optimizer\"][\"model\"]==\"Adam\":\n",
        "       optimizer_conv = optim.Adam(model_conv.parameters(),lr=Hyperparameter[\"optimizer\"][\"lr\"])\n",
        "\n",
        "    #optim.SGD(model_conv.fc.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # 7 에폭마다 0.1씩 학습률 감소\n",
        "\n",
        "    if Hyperparameter[\"scheduler\"][\"model\"]==\"StepLR\":\n",
        "      exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=Hyperparameter[\"scheduler\"][\"Period\"], gamma=Hyperparameter[\"scheduler\"][\"gamma\"])\n",
        "    elif Hyperparameter[\"scheduler\"][\"model\"]==\"ReduceLROnPlateau\":\n",
        "      exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv)\n",
        "\n",
        "    return model_conv,criterion,optimizer_conv,exp_lr_scheduler,Hyperparameter\n",
        "    \n",
        "  \n",
        "    \n",
        "  def RESNET18(self,Hyperparameter):\n",
        "\n",
        "    #resnet.py 166 line , 195, 279\n",
        "    \n",
        "    \"\"\"\n",
        "    Hyperparameter = {\n",
        "      \"model\":\"resnet18\",\n",
        "      \"weight\":\"IMAGENET1K_V1\",\n",
        "      \"Loss Function\":\"CrossEntropyLoss\",\n",
        "      \"optimizer\":{\"model\":\"Adam\",\"lr\":0.001,\"momentum\":0.9},\n",
        "      \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1},\n",
        "      \"data_feature\":{\"xtrain_angle\":[i for i in range(1,15)],\"xtest_angle\":[i for i in range(15,25)],\"ytrain_angle\":[0,30],\"ytest_angle\":[60]},\n",
        "      \"Domain_Generalization\":0, # Domain Generalization (도메인 일반화, 데이터 증진 or mixstyle 등)\n",
        "    },\n",
        "    \"\"\"\n",
        "    \n",
        "    model_conv = Resnet18(weights=Hyperparameter[\"weight\"])\n",
        "    for param in model_conv.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n",
        "    num_ftrs = model_conv.fc.in_features\n",
        "    model_conv.fc = nn.Linear(num_ftrs, len(self.class_names))\n",
        "\n",
        "    model_conv = model_conv.to(self.device)\n",
        "\n",
        "    if Hyperparameter[\"Loss Function\"]==\"CrossEntropyLoss\":\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n",
        "    if Hyperparameter[\"optimizer\"][\"model\"]==\"SGD\":\n",
        "      optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=Hyperparameter[\"optimizer\"][\"lr\"], momentum=Hyperparameter[\"optimizer\"][\"momentum\"])\n",
        "    elif Hyperparameter[\"optimizer\"][\"model\"]==\"Adam\":\n",
        "       optimizer_conv = optim.Adam(model_conv.fc.parameters(),lr=Hyperparameter[\"optimizer\"][\"lr\"])\n",
        "\n",
        "    #optim.SGD(model_conv.fc.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # 7 에폭마다 0.1씩 학습률 감소\n",
        "\n",
        "    if Hyperparameter[\"scheduler\"][\"model\"]==\"StepLR\":\n",
        "      exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=Hyperparameter[\"scheduler\"][\"Period\"], gamma=Hyperparameter[\"scheduler\"][\"gamma\"])\n",
        "\n",
        "    return model_conv,criterion,optimizer_conv,exp_lr_scheduler,Hyperparameter\n",
        "\n",
        "  def RESNET34(self,Hyperparameter):\n",
        "\n",
        "    \"\"\"\n",
        "    {\n",
        "      \"model\":\"resnet18\",\n",
        "      \"weight\":\"IMAGENET1K_V1\",\n",
        "      \"Loss Function\":\"CrossEntropyLoss\",\n",
        "      \"optimizer\":{\"model\":\"SGD\",\"lr\":0.001,\"momentum\":0.9},\n",
        "      \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1}\n",
        "    }\n",
        "    \"\"\"\n",
        "    #IMAGENET1K_V1\n",
        "    model_conv = Resnet34(weights=Hyperparameter[\"weight\"])\n",
        "    for param in model_conv.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n",
        "    num_ftrs = model_conv.fc.in_features\n",
        "    model_conv.fc = nn.Linear(num_ftrs, len(self.class_names))\n",
        "\n",
        "    model_conv = model_conv.to(self.device)\n",
        "\n",
        "    if Hyperparameter[\"Loss Function\"]==\"CrossEntropyLoss\":\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n",
        "    if Hyperparameter[\"optimizer\"][\"model\"]==\"SGD\":\n",
        "      optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=Hyperparameter[\"optimizer\"][\"lr\"], momentum=Hyperparameter[\"optimizer\"][\"momentum\"])\n",
        "    elif Hyperparameter[\"optimizer\"][\"model\"]==\"Adam\":\n",
        "       optimizer_conv = optim.Adam(model_conv.fc.parameters(),lr=Hyperparameter[\"optimizer\"][\"lr\"])\n",
        "\n",
        "    #optim.SGD(model_conv.fc.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # 7 에폭마다 0.1씩 학습률 감소\n",
        "\n",
        "    if Hyperparameter[\"scheduler\"][\"model\"]==\"StepLR\":\n",
        "      exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=Hyperparameter[\"scheduler\"][\"Period\"], gamma=Hyperparameter[\"scheduler\"][\"gamma\"])\n",
        "\n",
        "    return model_conv,criterion,optimizer_conv,exp_lr_scheduler,Hyperparameter\n",
        "\n",
        "  #아직 설정안됨\n",
        "  def ALEXNET(self,Hyperparameter):\n",
        "\n",
        "    \"\"\"\n",
        "    {\n",
        "      \"model\":\"alexnet\",\n",
        "      \"weight\":\"IMAGENET1K_V1\",\n",
        "      \"Loss Function\":\"CrossEntropyLoss\",\n",
        "      \"optimizer\":{\"model\":\"SGD\",\"lr\":0.001,\"momentum\":0.9},\n",
        "      \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1}\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    model_conv = alexnet(weights=Hyperparameter[\"weight\"])\n",
        "\n",
        "    #model_conv = alexnet(len(self.class_names))\n",
        "    #for param in model_conv.parameters():\n",
        "    #    param.requires_grad = True\n",
        "\n",
        "    # 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n",
        "    #num_ftrs = model_conv.fc.in_features\n",
        "    #model_conv.fc = nn.Linear(num_ftrs, len(self.class_names))\n",
        "\n",
        "    model_conv = model_conv.to(self.device)\n",
        "\n",
        "    if Hyperparameter[\"Loss Function\"]==\"CrossEntropyLoss\":\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n",
        "    if Hyperparameter[\"optimizer\"][\"model\"]==\"SGD\":\n",
        "      optimizer_conv = optim.SGD(model_conv.parameters(), lr=Hyperparameter[\"optimizer\"][\"lr\"], momentum=Hyperparameter[\"optimizer\"][\"momentum\"])\n",
        "    elif Hyperparameter[\"optimizer\"][\"model\"]==\"Adam\":\n",
        "       optimizer_conv = optim.Adam(model_conv.parameters(),lr=Hyperparameter[\"optimizer\"][\"lr\"])\n",
        "\n",
        "    #optim.SGD(model_conv.fc.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # 7 에폭마다 0.1씩 학습률 감소\n",
        "\n",
        "    if Hyperparameter[\"scheduler\"][\"model\"]==\"StepLR\":\n",
        "      exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=Hyperparameter[\"scheduler\"][\"Period\"], gamma=Hyperparameter[\"scheduler\"][\"gamma\"])\n",
        "\n",
        "    return model_conv,criterion,optimizer_conv,exp_lr_scheduler,Hyperparameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QbxBkNMkfSTo"
      },
      "outputs": [],
      "source": [
        "def START(epoch,batch_size=64,\n",
        "          Hyperparameter = {\n",
        "        \"model\":\"resnet18\",\n",
        "        \"weight\":\"IMAGENET1K_V1\",\n",
        "        \"Loss Function\":\"CrossEntropyLoss\",\n",
        "        \"optimizer\":{\"model\":\"Adam\",\"lr\":0.0001,\"momentum\":0.9},\n",
        "        \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1},\n",
        "        \"data_feature\":{\"ytrain_angle\":[0,30],\"ytest_angle\":[60]},\n",
        "        \"Domain_Generalization\":0, # Domain Generalization (도메인 일반화, 데이터 증진 or mixstyle 등)\n",
        "        \"Data_augmentation\":{\"image_rotation\":0,\"ColorJitter\":0,\"RandomHorizontalFlip\":0,\"RandomVerticalFlip\":0,\"RandomGrayscale\":0}\n",
        "        \n",
        "      },save_file_name=\"alexnet_sample_data/\",inital_path=\"D:/essay/\"):\n",
        "    \n",
        "    MPI=market_product_identification(\n",
        "        inital_path=inital_path,\n",
        "        using_category=['prod_nm','file_name','yangle','path','rotation'],\n",
        "        data_feature=Hyperparameter[\"data_feature\"],\n",
        "        Data_augmentation=Hyperparameter[\"Data_augmentation\"]\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "    train_v={\"label_data\":MPI.train,\"transform\":MPI.train_transform}\n",
        "    test_v={\"label_data\":MPI.test,\"transform\":MPI.test_transform}\n",
        "    #train_v={\"transform\":MPI.train_transform}\n",
        "    #test_v={\"transform\":MPI.test_transform}\n",
        "\n",
        " \n",
        "\n",
        "    Train,Test = produce_Dataset(train_v,test_v,batch_size,Hyperparameter[\"data_feature\"][\"ytest_angle\"][0],MPI.a0_path,MPI.a30_path,MPI.a60_path,MPI.nl_idx,Hyperparameter[\"Data_augmentation\"])\n",
        "\n",
        "    learning_dataset={\"train\":Train[\"dataset\"],\"test\":Test[\"dataset\"]}\n",
        "    learning_dataloader={\"train\":Train[\"dataloader\"],\"test\":Test[\"dataloader\"]}\n",
        "    learning_dataset_size={\"train\":len(Train[\"dataset\"]),\"test\":len(Test[\"dataset\"])}\n",
        "\n",
        "    #new labeling object_type\n",
        "    class_names=[i for i in range(1,len(MPI.object_type)+1)]\n",
        "\n",
        "    dl_model=dl_Model(class_names,device)\n",
        "\n",
        "    model_conv,criterion,optimizer_conv,exp_lr_scheduler,Hyperparameter=dl_model.produce_model(Hyperparameter)\n",
        "\n",
        "\n",
        "\n",
        "    #torch.backends.cudnn.enabled = False\n",
        "    Epoch=epoch\n",
        "    file_n=save_file_name\n",
        "\n",
        "    #example\n",
        "    #Hyperparameter={\"model\":\"resnet18\",\"Loss Function\":\"CrossEntropyLoss\",\"optimizer\":{\"model\":\"SGD\",\"lr\":0.001,\"momentum\":0.9},\"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1}}\n",
        "\n",
        "    P=inital_path+\"result/\"+file_n\n",
        "\n",
        "    #result file produce\n",
        "    os.mkdir(P)\n",
        "\n",
        "    Hyperparameter_path=P+\"Hyperparameter.txt\"\n",
        "\n",
        "    #Hyperparameter text file produce\n",
        "    f=open(Hyperparameter_path,\"w\")\n",
        "    f.close()\n",
        "    f=open(Hyperparameter_path,\"a\")\n",
        "    f.write(f'model is {Hyperparameter[\"model\"]}.\\n')\n",
        "    f.write(f'weight is {Hyperparameter[\"weight\"]}.\\n')\n",
        "    f.write(f'epoch is {epoch}.\\n')\n",
        "    f.write(f'batch size is {batch_size}.\\n')\n",
        "    f.write(f'ytrain_angle is {Hyperparameter[\"data_feature\"][\"ytrain_angle\"]}.\\n')\n",
        "    f.write(f'ytest_angle is {Hyperparameter[\"data_feature\"][\"ytest_angle\"]}.\\n')\n",
        "    f.write(f'Loss Function is {Hyperparameter[\"Loss Function\"]}.\\n')\n",
        "    # \"Domain_Generalization\":1, # Domain Generalization (도메인 일반화, 데이터 증진 or mixstyle 등)\n",
        "    #\"Data_augmentation\":{\"image_rotation\":0,\"ColorJitter\":0,\"RandomHorizontalFlip\":0,\"RandomVerticalFlip\":0,\"RandomGrayscale\":0}\n",
        "    f.write(f'Domain_Generalization is {Hyperparameter[\"Domain_Generalization\"]}.\\n')\n",
        "    f.write(f'Data_augmentation\\n')\n",
        "    f.write(f'image_rotation is {Hyperparameter[\"Data_augmentation\"][\"image_rotation\"]}.\\n')\n",
        "    f.write(f'ColorJitter is {Hyperparameter[\"Data_augmentation\"][\"ColorJitter\"]}.\\n')\n",
        "    f.write(f'RandomHorizontalFlip is {Hyperparameter[\"Data_augmentation\"][\"RandomHorizontalFlip\"]}.\\n')\n",
        "    f.write(f'RandomGrayscale is {Hyperparameter[\"Data_augmentation\"][\"RandomGrayscale\"]}.\\n')\n",
        "\n",
        "    f.write(f'optimizer is {Hyperparameter[\"optimizer\"][\"model\"]}. lr is {Hyperparameter[\"optimizer\"][\"lr\"]}, momentum is {Hyperparameter[\"optimizer\"][\"momentum\"]}.\\n')\n",
        "    f.write(f'scheduler is {Hyperparameter[\"scheduler\"][\"model\"]}. Period is {Hyperparameter[\"scheduler\"][\"Period\"]}, gamma is {Hyperparameter[\"scheduler\"][\"gamma\"]}.\\n')\n",
        "\n",
        "    f.close()\n",
        "\n",
        "    # loss,acc\n",
        "    TRAIN=[]\n",
        "    TEST=[]\n",
        "\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "    best_loss=0.0\n",
        "    idx=0\n",
        "    #print(learning_dataset_size[\"train\"])\n",
        "    #print(learning_dataset_size[\"val\"])\n",
        "    #print(learning_dataset_size[\"test\"])\n",
        "\n",
        "    train_size=[]\n",
        "    test_size=[]\n",
        "    #print(\"##@@##\")\n",
        "    #print(MPI.object_stack)\n",
        "    for i in range(len(MPI.object_stack)):\n",
        "        QE=Hyperparameter['data_feature']['ytrain_angle']#MPI.object_stack[i][Hyperparameter['data_feature']['ytrain_angle']]\n",
        "        #print(QE)\n",
        "        train_size.append(MPI.object_stack[i][str(QE[0])]+MPI.object_stack[i][str(QE[1])])\n",
        "        test_size.append(MPI.object_stack[i][str(Hyperparameter['data_feature']['ytest_angle'][0])])\n",
        "\n",
        "    #print(train_size)\n",
        "    #print(test_size)\n",
        "\n",
        "\n",
        "    for epoch in range(Epoch):\n",
        "        print(f'Epoch {epoch}/{Epoch - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        #print(\"train\")\n",
        "        #print(\"=\"*20)\n",
        "\n",
        "        #return epoch_loss,epoch_acc,model,optimizer,scheduler\n",
        "        #print(\"XCVXCV\")\n",
        "        epoch_loss,epoch_acc,model_conv,optimizer_conv,exp_lr_scheduler=train_model(model_conv, \n",
        "                                                                                    criterion, \n",
        "                                                                                    optimizer_conv,\n",
        "                                                                                    exp_lr_scheduler, \n",
        "                                                                                    learning_dataloader[\"train\"],\n",
        "                                                                                    learning_dataset_size[\"train\"],\n",
        "                                                                                    batch_size,train_size,Hyperparameter[\"Data_augmentation\"])\n",
        "        TRAIN.append([epoch_loss,epoch_acc])\n",
        "\n",
        "        #print(\"val\")\n",
        "        #print(\"=\"*20)\n",
        "\n",
        "        #return epoch_loss,epoch_acc,model,optimizer,scheduler\n",
        "\n",
        "        # 모델을 깊은 복사(deep copy)함\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            idx=epoch\n",
        "            best_loss=epoch_loss\n",
        "\n",
        "        torch.save(model_conv.state_dict(), P+'/checkpoint_epoch_'+str(epoch+1)+'.pth')\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "\n",
        "    print()\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best train Acc: {best_acc:4f}')\n",
        "\n",
        "    result_val_text_path=P+\"/result_train.txt\"\n",
        "\n",
        "    #val result save\n",
        "    f=open(result_val_text_path,\"w\")\n",
        "    f.close()\n",
        "    f=open(result_val_text_path,\"a\")\n",
        "    for i in range(Epoch):\n",
        "        f.write(f\"epoch_{i+1}\\n\")\n",
        "        f.write(f\"epoch_{i+1} train loss : {TRAIN[i][0]}, train acc : {TRAIN[i][1]}\\n\")\n",
        "\n",
        "    f.write(\"\\n\")\n",
        "    f.write(f\"best val acc's epoch is epoch_{idx+1}.\\n\")\n",
        "    f.write(f\"best val acc is {best_acc} and this acc's loss is {best_loss}.\\n\")\n",
        "    f.close()\n",
        "\n",
        "    ############################################\n",
        "\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "    best_loss=0.0\n",
        "    idx=0\n",
        "\n",
        "    for epoch in range(Epoch):\n",
        "        print(f'Epoch {epoch}/{Epoch - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        #print(\"test\")\n",
        "        #print(\"=\"*20)\n",
        "\n",
        "        model_conv.load_state_dict(torch.load(P+'/checkpoint_epoch_'+str(epoch+1)+'.pth'))\n",
        "        epoch_loss,epoch_acc,model_conv=test_model(model_conv, criterion, learning_dataloader[\"test\"],learning_dataset_size[\"test\"],test_size,Hyperparameter[\"Data_augmentation\"])\n",
        "        # 모델을 깊은 복사(deep copy)함\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            idx=epoch\n",
        "            best_loss=epoch_loss\n",
        "\n",
        "        #torch.save(model_conv.state_dict(), P+'/checkpoint_epoch_'+str(epoch+1)+'.pth')\n",
        "        TEST.append([epoch_loss,epoch_acc])\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    #print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best test Acc: {best_acc:4f}')\n",
        "\n",
        "\n",
        "    f=open(P+\"/result_test.txt\",\"w\")\n",
        "    f.close()\n",
        "    f=open(P+\"/result_test.txt\",\"a\")\n",
        "    for i in range(Epoch):\n",
        "      f.write(f\"epoch_{i+1}\\n\")\n",
        "      f.write(f\"epoch_{i+1} test loss : {TEST[i][0]}, test acc : {TEST[i][1]}\\n\")\n",
        "\n",
        "    f.write(\"\\n\")\n",
        "    f.write(f\"best test acc's epoch is epoch_{idx+1}.\\n\")\n",
        "    f.write(f\"best test acc is {best_acc} and this acc's loss is {best_loss}.\\n\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "J8C2bHpnfTEI",
        "outputId": "ee12f83c-3adb-4b2f-f067-fb25caf3c5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 1.7573 Acc: 0.3526\n",
            "\n",
            "Training complete in 0m 25s\n",
            "Best train Acc: 0.352593\n",
            "Epoch 0/0\n",
            "----------\n",
            "test Loss: 1.5363 Acc: 0.5200\n",
            "Best test Acc: 0.520045\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 1.8393 Acc: 0.2873\n",
            "\n",
            "Training complete in 0m 23s\n",
            "Best train Acc: 0.287262\n",
            "Epoch 0/0\n",
            "----------\n",
            "test Loss: 1.5625 Acc: 0.4600\n",
            "Best test Acc: 0.459952\n",
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 1.8170 Acc: 0.3058\n",
            "\n",
            "Training complete in 0m 23s\n",
            "Best train Acc: 0.305846\n",
            "Epoch 0/0\n",
            "----------\n",
            "test Loss: 1.6874 Acc: 0.4708\n",
            "Best test Acc: 0.470766\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "기본 설정\n",
        "F라는 폴더안에 파일들이 있을때 inital_path 에 F 폴더 위치를 설정해줘야함\n",
        "모든 path 는 뒤에 \\를 붙여야함\n",
        "F 폴더 안에는 dataset 이라는 데이터 파일, result 폴더가 있어야 함\n",
        "\n",
        "\n",
        "1분 16초에 5epoch rotation x 가 돌기 때문에 epoch 해도 얼마 안걸릴듯\n",
        "\n",
        "vsc 에선 desenet 터짐\n",
        "resnet 은 batch_size 64 도 돌지만 나머지는 돌지 않기 때문에 colab 에서 16 이하로 돌려야됨\n",
        "gpu 메모리 초과가 뜨면 batch_size 를 줄여라\n",
        "batch_size 줄이고 lr 도 줄이고\n",
        "https://inhovation97.tistory.com/32\n",
        "https://blog.joonas.io/193\n",
        "\"\"\"\n",
        "\n",
        "angle_stack=[0,30,60]\n",
        "for i in range(3):\n",
        "  ytrain_angle=[]\n",
        "  ytest_angle=[angle_stack[i]]\n",
        "  for g in range(3):\n",
        "    if i!=g:\n",
        "      ytrain_angle.append(angle_stack[g])\n",
        "\n",
        "  #print(ytrain_angle)\n",
        "  #print(ytest_angle)\n",
        "  #print(f\"ytrain_angle : {ytrain_angle}.\")\n",
        "  #print(f\"ytest_angle : {ytest_angle}.\")\n",
        "\n",
        "\n",
        "  START(\n",
        "      epoch = 1,batch_size=16,\n",
        "      Hyperparameter = {\n",
        "        \"model\":\"resnet18\",\n",
        "        \"weight\":\"IMAGENET1K_V1\",\n",
        "        \"Loss Function\":\"CrossEntropyLoss\",\n",
        "        \"optimizer\":{\"model\":\"Adam\",\"lr\":0.0001,\"momentum\":0.9},\n",
        "        \"scheduler\":{\"model\":\"StepLR\",\"Period\":7,\"gamma\":0.1},\n",
        "        \"data_feature\":{\"ytrain_angle\":ytrain_angle,\"ytest_angle\":ytest_angle},\n",
        "        \"Domain_Generalization\":1, # Domain Generalization (도메인 일반화, 데이터 증진 or mixstyle 등)\n",
        "        \"Data_augmentation\":{\"image_rotation\":1,\"ColorJitter\":1,\"RandomHorizontalFlip\":1,\"RandomVerticalFlip\":1,\"RandomGrayscale\":1}\n",
        "        \n",
        "      },\n",
        "      save_file_name = \"test1_\"+str(angle_stack[i])+\"/\",\n",
        "      inital_path = \"D:/essay/thesis/\"#\"/content/drive/MyDrive/01_고원규/\"\n",
        "      \n",
        "      )\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl--d8nXgv5l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
